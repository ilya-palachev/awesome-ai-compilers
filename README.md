# Yet another survey of literature on compilers for AI models

This survey is intended to cover research on compilers for AI domain. Some of these compilers are widely known as NPU/TPU compilers.

It's built not by a professional, just for studying.

## What is this similar to?

Of course, this survey is not the first one in this domain. Here is the quickly found list of similar GitHub surveys. You're better to see them first:

- :star: [awesome-tensor-compilers](https://github.com/merrymercy/awesome-tensor-compilers)
- [DL-on-Silicon](https://github.com/gopala-kr/DL-on-Silicon)
- [SpikeNN](https://github.com/gopala-kr/Quantum-Dots/blob/5f678284a308292a44fa7578814860528c5e1d04/05-BCI_Neuromorphic/SpikeNN.md)

## What is not covered here?

Several closely related adjacent areas are not covered here:

- AI for compilers, see [awesome-machine-learning-in-compilers](https://github.com/zwang4/awesome-machine-learning-in-compilers)
- AI chips, see [AI-Chip](https://github.com/basicmi/AI-Chip)
- AI for software engineering, see [Allamanis survey](https://ml4code.github.io/) and [former src-d survey](https://github.com/src-d/awesome-machine-learning-on-source-code)

## Existing paper surveys

- Li et al. [The Deep Learning Compiler: A Comprehensive Survey](https://arxiv.org/pdf/2002.03794.pdf) (Beihang & Tsinghua Universities. arXiv, 2020)
  > To the best of our knowledge, this is the first paper that provides a comprehensive survey on the design of DL compiler.
